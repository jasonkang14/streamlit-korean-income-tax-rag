import streamlit as st
from dotenv import load_dotenv
from llm import get_ai_response

# Set the page configuration
st.set_page_config(page_title="ì†Œë“ì„¸ ì±—ë´‡", page_icon="ğŸ¤–")

# Display the title and caption
st.title("ğŸ¤– ì†Œë“ì„¸ ì±—ë´‡")
st.caption("ì†Œë“ì„¸ì— ê´€ë ¨ëœ ëª¨ë“ ê²ƒì„ ë‹µí•´ë“œë¦½ë‹ˆë‹¤!")

def initialize_session_state():
    """Initialize session state variables."""
    if 'env_loaded' not in st.session_state:
        load_dotenv()
        st.session_state['env_loaded'] = True
    if 'message_list' not in st.session_state:
        st.session_state.message_list = []

def display_messages():
    """Display all previous messages."""
    for message in st.session_state.message_list:
        with st.chat_message(message["role"]):
            st.write(message["content"])

def handle_user_input():
    """Handle new user input and generate AI response."""
    if user_question := st.chat_input(placeholder="ì†Œë“ì„¸ì— ê´€ë ¨ëœ ê¶ê¸ˆí•œ ë‚´ìš©ë“¤ì„ ë§ì”€í•´ì£¼ì„¸ìš”!"):
        # Display the user's message
        with st.chat_message("user"):
            st.write(user_question)
        st.session_state.message_list.append({"role": "user", "content": user_question})

        # Generate and display AI response
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤"):
            try:
                ai_response = get_ai_response(user_question)
                with st.chat_message("ai"):
                    st.write(ai_response)
                st.session_state.message_list.append({"role": "ai", "content": ai_response})
            except Exception as e:
                st.error(f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# Initialize session state
initialize_session_state()

# Display all previous messages
display_messages()

# Handle new user input
handle_user_input()